# Awesome-Video-Instance-Segmentation
A list of video instance segmentation (VIS) papers 

# Awesome Video Instance Segmentation [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A list of Video Instance Segmentation (VIS) Research Papers.
Any suggestion stars ‚≠ê , comments & sharing üòÄ are welcome!!

```diff
- 2023.05.10: Recent papers (from 2023) 
- Welcome to add if any information is missed. 
```
---

## Introduction

**Video Instance Segmentation** aims at **detecting, segmenting, and tracking every pixel of object instances simultaneously in a given video.** 

**Video Instance Segmentation** (VIS) methods can be categorized as online, Semi-Online or Offline methods. 
- ***Online methods***  take as input a video frame by frame, detecting and segmenting objects per frame while tracking instances and optimizing results
across frames.
- ***Offline methods***  in contrast, take the whole video as input and generate the instance sequence of the entire video with a single step.
- ***Semi-online*** that focus on placing multiple frames in a short clip to strengthen intra-clip tracking similar to offline methods.

|                                                                                                     |      | ALGORITHM           | DATA                       | TRAINING                                                                                                                                                                                                                                                                       | RESOURCES                        |
| --------------------------------------------------------------------------------------------------- | ---- | ------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------- |
| PAPER TITLE                                                                                         | YEAR | CONFERENCE, JOURNAL | PROBLEM                    | RELEVANCE                                                                                                                                                                                                                                                                      | TRACKING                         | DATASET | CODE AVAILABLE | PAPER LINK | GITHUB LINK | PROJECT LINK |
|                                                                                                     |      |                     | (Universal / Task)         |                                                                                                                                                                                                                                                                                | (Online / Offline)               |  |  |  |  |  |
| Universal Instance Perception as Object Discovery and Retrieval                                     | 2023 | CVPR                | Universal - VIS, VOS, MOTS | Large Language model feature fusion with Video Segmentation, UNINEXT reformulates diverse instance perception tasks<br>into a unified object discovery and retrieval paradigm and<br>can flexibly perceive different types of objects by simply<br>changing the input prompts. | Online, and post-processing free | Youtube-VIS 2019, OVIS | YES | [https://arxiv.org/pdf/2303.06674v1.pdf](https://arxiv.org/pdf/2303.06674v1.pdf) | [https://github.com/MasterBin-IIAU/UNINEXT](https://github.com/MasterBin-IIAU/UNINEXT) |  |
| MDQE: Mining Discriminative Query Embeddings to Segment Occluded Instances on Challenging Videos    | 2023 | CVPR                |                            | Based on Box VIS                                                                                                                                                                                                                                                               |                                  |  | NO | [https://arxiv.org/pdf/2303.14618.pdf](https://arxiv.org/pdf/2303.14618.pdf) | [https://github.com/minghanli/mdqe_cvpr2023](https://github.com/minghanli/mdqe_cvpr2023) (Code Not Available Yet) |  |
| Mask-Free Video Instance Segmentation                                                               | 2023 | CVPR                |                            |                                                                                                                                                                                                                                                                                |                                  |  | YES | [https://arxiv.org/pdf/2303.15904.pdf](https://arxiv.org/pdf/2303.15904.pdf) | [https://github.com/syscv/maskfreevis](https://github.com/syscv/maskfreevis) |  |
| Tube-Link: A Flexible Cross Tube Baseline for Universal Video Segmentation                          | 2023 | CVPR                | Universal                  | KD: Contrastive training over tubes and assignment strategy versus IDOL like contrastive training over per object extented to clip for each tube                                                                                                                               | Semi Online                      |  |  | [https://arxiv.org/pdf/2303.12782v1.pdf](https://arxiv.org/pdf/2303.12782v1.pdf) | [https://github.com/lxtGH/Tube-Link](https://github.com/lxtGH/Tube-Link) (Code Not Available Yet) |  |
| Video Instance Segmentation in an Open-World                                                        | 2023 | CVPR                | VIS - Unseen Categories    | Unknown class - open world formulation                                                                                                                                                                                                                                         |                                  |  |  | [https://arxiv.org/pdf/2304.01200v1.pdf](https://arxiv.org/pdf/2304.01200v1.pdf) | [https://github.com/OmkarThawakar/OWVISFormer](https://github.com/OmkarThawakar/OWVISFormer') |  |
| InstMove: Instance Motion for Object-centric Video Segmentation                                     | 2023 | CVPR                | VIS, VOS                   | instance-level motion model                                                                                                                                                                                                                                                    |                                  | SOTA OVIS |  | [https://arxiv.org/pdf/2303.08132.pdf](https://arxiv.org/pdf/2303.08132.pdf) | No code available yet. To be released in the VNEXT repository |  |
| TarViS: A Unified Approach for Target-based Video Segmentation                                      | 2023 | CVPR                | Claims SOTA - Universal    | Temporal Neck for Video Understanding and Single model for multiple tasks                                                                                                                                                                                                      |                                  |  |  | [https://arxiv.org/pdf/2301.02657.pdf](https://arxiv.org/pdf/2301.02657.pdf) | No code available yet. |  |
| A Generalized Framework for Video Instance Segmentation                                             | 2023 | ARXIV               | Claims SOTA                | Based on VITA                                                                                                                                                                                                                                                                  |                                  |  |  | [https://arxiv.org/pdf/2211.08834.pdf](https://arxiv.org/pdf/2211.08834.pdf) | [https://github.com/miranheo/GenVIS](https://github.com/miranheo/GenVIS) |  |
| Masked-attention Mask Transformer for Universal Image Segmentation                                  | 2022 | CVPR                | VIS                        | Mask based attention module                                                                                                                                                                                                                                                    | Mask2Former                      | YTVIS 2019 | YES | [](https://arxiv.org/pdf/2112.01527.pdf)[https://arxiv.org/pdf/2112.01527.pdf](https://arxiv.org/pdf/2112.01527.pdf) | [](https://bowenc0221.github.io/mask2former/)[https://bowenc0221.github.io/mask2former/](https://bowenc0221.github.io/mask2former/) |  |
| Instance As Identity: A Generic Online Paradigm for Video Instance Segmentation                     | 2022 | ECCV                | VIS                        |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://arxiv.org/pdf/2208.03079v2.pdf](https://arxiv.org/pdf/2208.03079v2.pdf) |  | [https://paperswithcode.com/paper/instanceformer-an-online-video-instance](https://paperswithcode.com/paper/instanceformer-an-online-video-instance) |
| Temporally Efficient Vision Transformer for Video Instance Segmentation                             | 2022 | CVPR                |                            |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.pdf) |  |  |
| InstanceFormer: An Online Video Instance Segmentation Framework                                     | 2022 | ECCV                |                            |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://arxiv.org/pdf/2208.10547v1.pdf](https://arxiv.org/pdf/2208.10547v1.pdf) | [https://github.com/rajatkoner08/InstanceFormer](https://github.com/rajatkoner08/InstanceFormer) |  |
| TIVE: A Toolbox for Identifying Video Instance Segmentation Errors                                  | 2022 | Arxiv               | VIS Metric                 |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://arxiv.org/pdf/2210.08856v1.pdf](https://arxiv.org/pdf/2210.08856v1.pdf) |  |  |
| STC: Spatio-Temporal Contrastive Learning for Video Instance Segmentation                           | 2022 | ECCV Workshop       |                            |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://link.springer.com/chapter/10.1007/978-3-031-25069-9_35](https://link.springer.com/chapter/10.1007/978-3-031-25069-9_35) |  |  |
| Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation                 | 2021 | NEURIPS             | VIS                        |                                                                                                                                                                                                                                                                                | PCAN                             |  |  | [https://papers.nips.cc/paper/2021/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf](https://papers.nips.cc/paper/2021/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf) |  |  |
| Spatial Feature Calibration and Temporal Fusion for Effective One-stage Video Instance Segmentation | 2021 | CVPR                |                            |                                                                                                                                                                                                                                                                                |                                  |  |  | [http://www4.comp.polyu.edu.hk/~cslzhang/papers.htm](http://www4.comp.polyu.edu.hk/~cslzhang/papers.htm) | [https://github.com/MinghanLi/STMask](https://github.com/MinghanLi/STMask) |  |
| Crossover Learning for Fast Online Video Instance Segmentation                                      | 2021 | ICCV                |                            |                                                                                                                                                                                                                                                                                |                                  |  |  | [https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Crossover_Learning_for_Fast_Online_Video_Instance_Segmentation_ICCV_2021_paper.pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Crossover_Learning_for_Fast_Online_Video_Instance_Segmentation_ICCV_2021_paper.pdf) | [https://github.com/hustvl/CrossVIS](https://github.com/hustvl/CrossVIS) |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
|                                                                                                     |      |                     |                            |                                                                                                                                                                                                                                                                                |                                  |  |  |  |  |  |
